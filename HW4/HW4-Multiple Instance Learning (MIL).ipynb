{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36210222",
   "metadata": {},
   "source": [
    "# MULTIPLE INSTANCE LEARNING (MIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d30297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b63fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 168)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_musk</th>\n",
       "      <th>bag_id</th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>...</th>\n",
       "      <th>F156</th>\n",
       "      <th>F157</th>\n",
       "      <th>F158</th>\n",
       "      <th>F159</th>\n",
       "      <th>F160</th>\n",
       "      <th>F161</th>\n",
       "      <th>F162</th>\n",
       "      <th>F163</th>\n",
       "      <th>F164</th>\n",
       "      <th>F165</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-109</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>-88</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>144</td>\n",
       "      <td>43</td>\n",
       "      <td>-30</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_musk  bag_id  F0   F1   F2  F3   F4  F5  F6   F7  ...  F156  F157  F158  \\\n",
       "0        1       1  42 -198 -109 -75 -117  11  23  -88  ...  -238   -74  -129   \n",
       "1        1       1  42 -191 -142 -65 -117  55  49 -170  ...  -238  -302    60   \n",
       "2        1       1  42 -191 -142 -75 -117  11  49 -161  ...  -238   -73  -127   \n",
       "3        1       1  42 -198 -110 -65 -117  55  23  -95  ...  -238  -302    60   \n",
       "4        1       2  42 -198 -102 -75 -117  10  24  -87  ...  -238   -73  -127   \n",
       "\n",
       "   F159  F160  F161  F162  F163  F164  F165  \n",
       "0  -120   -38    30    48   -37     6    30  \n",
       "1  -120   -39    31    48   -37     5    30  \n",
       "2  -120   -38    30    48   -37     5    31  \n",
       "3  -120   -39    30    48   -37     6    30  \n",
       "4    51   128   144    43   -30    14    26  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"is_musk\", \"bag_id\"] + [f\"F{i}\" for i in range(166)]\n",
    "data = pd.read_csv(\"./Musk1.csv\", names=col_names)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d6107b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.bag_id.value_counts().hist()\n",
    "plt.title(\"# of Observations in Bags\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7113eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    92.000000\n",
       "mean      5.173913\n",
       "std       6.432419\n",
       "min       2.000000\n",
       "25%       2.000000\n",
       "50%       4.000000\n",
       "75%       5.000000\n",
       "max      40.000000\n",
       "Name: bag_id, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.bag_id.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b8958",
   "metadata": {},
   "source": [
    "The # of observation in each bag is not the same therefore we cannot simply represent it in a wide manner where the data has 166*(N observation in a bag). We need to figure out another way to do it. As the instructions say one option is to use the mean as the bag level representation. We will use the mean representation as the baseline features and evaluate its performance in every algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e37cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bag_id</th>\n",
       "      <th>is_musk</th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>...</th>\n",
       "      <th>F156</th>\n",
       "      <th>F157</th>\n",
       "      <th>F158</th>\n",
       "      <th>F159</th>\n",
       "      <th>F160</th>\n",
       "      <th>F161</th>\n",
       "      <th>F162</th>\n",
       "      <th>F163</th>\n",
       "      <th>F164</th>\n",
       "      <th>F165</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-194.500000</td>\n",
       "      <td>-125.750000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>-128.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-238.000000</td>\n",
       "      <td>-187.75</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-120.000000</td>\n",
       "      <td>-38.500000</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>-37.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>30.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-194.500000</td>\n",
       "      <td>-122.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-238.000000</td>\n",
       "      <td>-186.25</td>\n",
       "      <td>-32.5</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>-30.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-166.000000</td>\n",
       "      <td>-102.500000</td>\n",
       "      <td>-30.500000</td>\n",
       "      <td>-116.5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>-142.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-235.500000</td>\n",
       "      <td>-57.50</td>\n",
       "      <td>-45.5</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>120.500000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>-32.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>-154.666667</td>\n",
       "      <td>-77.333333</td>\n",
       "      <td>-42.333333</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-237.333333</td>\n",
       "      <td>-142.00</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-80.333333</td>\n",
       "      <td>-33.666667</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>-38.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>32.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>-72.500000</td>\n",
       "      <td>-102.000000</td>\n",
       "      <td>-25.250000</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-143.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-237.750000</td>\n",
       "      <td>-117.25</td>\n",
       "      <td>-60.5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.750000</td>\n",
       "      <td>136.750000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>-26.750000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>36.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bag_id  is_musk         F0          F1          F2         F3     F4  \\\n",
       "0       1      1.0  42.000000 -194.500000 -125.750000 -70.000000 -117.0   \n",
       "1       2      1.0  42.000000 -194.500000 -122.000000 -70.000000 -117.0   \n",
       "2       3      1.0  42.000000 -166.000000 -102.500000 -30.500000 -116.5   \n",
       "3       4      1.0  42.666667 -154.666667  -77.333333 -42.333333 -117.0   \n",
       "4       5      1.0  61.500000  -72.500000 -102.000000 -25.250000  -34.0   \n",
       "\n",
       "          F5         F6     F7  ...        F156    F157  F158        F159  \\\n",
       "0  33.000000  36.000000 -128.5  ... -238.000000 -187.75 -34.0 -120.000000   \n",
       "1  33.000000  36.250000 -128.0  ... -238.000000 -186.25 -32.5   51.000000   \n",
       "2   5.000000  27.500000 -142.5  ... -235.500000  -57.50 -45.5   13.000000   \n",
       "3  22.333333  21.666667 -132.0  ... -237.333333 -142.00 -15.0  -80.333333   \n",
       "4  19.000000  29.000000 -143.5  ... -237.750000 -117.25 -60.5    5.000000   \n",
       "\n",
       "         F160        F161       F162       F163       F164       F165  \n",
       "0  -38.500000   30.250000  48.000000 -37.000000   5.500000  30.250000  \n",
       "1  126.500000  143.500000  42.750000 -30.250000  14.000000  26.500000  \n",
       "2  120.500000  133.500000  55.500000 -32.500000   2.000000  16.500000  \n",
       "3  -33.666667   31.333333  50.333333 -38.333333   5.333333  32.333333  \n",
       "4   75.750000  136.750000  68.500000 -26.750000  -0.250000  36.750000  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_data = data.groupby(\"bag_id\").mean().reset_index()\n",
    "mean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe306bb5",
   "metadata": {},
   "source": [
    "## Using Distribution Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f0b8b",
   "metadata": {},
   "source": [
    "Constructing the representations using the feature distributions in the bag makes sense. One way to embed the distribution in our features is using the min max valeus in the bag additional to the mean. Also, I think that # of observations in each bag can be a usefull feature especially if we use a tree based algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783f4873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Shape:  (92, 501)\n"
     ]
    }
   ],
   "source": [
    "min_data = data.drop(columns=\"is_musk\").groupby(\"bag_id\").min().reset_index()\n",
    "min_data.columns = [x+\"_MIN\" if x.startswith(\"F\") else x for x in min_data]\n",
    "\n",
    "max_data = data.drop(columns=\"is_musk\").groupby(\"bag_id\").max().reset_index()\n",
    "max_data.columns = [x+\"_MAX\" if x.startswith(\"F\") else x for x in max_data]\n",
    "\n",
    "n_observations = data.groupby(\"bag_id\").size().reset_index().rename(columns={0:\"N\"})\n",
    "\n",
    "min_max_mean_data = mean_data.merge(min_data).merge(max_data).merge(n_observations)\n",
    "print(\"New Data Shape: \", min_max_mean_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a4dac",
   "metadata": {},
   "source": [
    "One imporovement to this method is to enhance the distribution information adding the missing quartiles. With these values we aim to represent the distribution in our features better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b4d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Shape:  (92, 833)\n"
     ]
    }
   ],
   "source": [
    "q25_data = data.drop(columns=\"is_musk\").groupby(\"bag_id\").quantile(0.25).reset_index()\n",
    "q25_data.columns = [x+\"_Q25\" if x.startswith(\"F\") else x for x in q25_data]\n",
    "\n",
    "q75_data = data.drop(columns=\"is_musk\").groupby(\"bag_id\").max().reset_index()\n",
    "q75_data.columns = [x+\"_Q75\" if x.startswith(\"F\") else x for x in q75_data]\n",
    "\n",
    "dist_data = min_max_mean_data.merge(q25_data).merge(q75_data)\n",
    "\n",
    "# std_data = data.drop(columns=\"is_musk\").groupby(\"bag_id\").std().reset_index()\n",
    "# std_data.columns = [x+\"_STD\" if x.startswith(\"F\") else x for x in std_data]\n",
    "# dist_data = min_max_mean_data.merge(std_data)\n",
    "\n",
    "print(\"New Data Shape: \", dist_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e678db",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0875be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf': [1, 3, 7],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'n_estimators': [100, 250, 500, 750],\n",
    "    \"random_state\":[3136],\n",
    "    \"n_jobs\":[-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b124138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RF', 'Mean Data', 0.8344444444444445]\n",
      "['RF', 'Min Max Mean Data', 0.8566666666666667]\n",
      "['RF', 'Dist Data', 0.8244444444444445]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "names = [\"Mean Data\", \"Min Max Mean Data\", \"Dist Data\"]\n",
    "X_vals = [\n",
    "    mean_data.drop(columns=[\"bag_id\", \"is_musk\"]),\n",
    "    min_max_mean_data.drop(columns=[\"bag_id\", \"is_musk\"]),\n",
    "    dist_data.drop(columns=[\"bag_id\", \"is_musk\"]),\n",
    "]\n",
    "y_vals = [mean_data.is_musk, min_max_mean_data.is_musk, dist_data.is_musk]\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# We need to tune the classifier in this step\n",
    "# If I left a validation set separetely my predictions will be biased in that part of the train data\n",
    "# Therefore I pass will do a grid search in each cross validation step. With 3 cv it shouldn't take much time\n",
    "# Since we got a small amount of data\n",
    "grid_searher = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "for X, y, name in zip(X_vals, y_vals, names):\n",
    "\n",
    "    cvs = cross_val_score(\n",
    "        estimator=grid_searher, \n",
    "        X=X, \n",
    "        y=y, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=10\n",
    "    )\n",
    "\n",
    "    line = [\"RF\", name, cvs.mean()]\n",
    "    results.append(line)\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d7861",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d50cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Log Reg', 'Mean Data', 0.8588888888888888]\n",
      "['Log Reg', 'Min Max Mean Data', 0.8688888888888888]\n",
      "['Log Reg', 'Dist Data', 0.8577777777777778]\n",
      "['Log Reg l2', 'Mean Data', 0.8477777777777777]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harunkivril/anaconda3/envs/forelux_torch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Log Reg l2', 'Min Max Mean Data', 0.9111111111111111]\n",
      "['Log Reg l2', 'Dist Data', 0.9111111111111111]\n"
     ]
    }
   ],
   "source": [
    "logreg_none = LogisticRegression(penalty=\"none\", max_iter=1000)\n",
    "\n",
    "for X, y, name in zip(X_vals, y_vals, names):\n",
    "\n",
    "    cvs = cross_val_score(\n",
    "        estimator=logreg_none, \n",
    "        X=X, \n",
    "        y=y, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=10\n",
    "    )\n",
    "\n",
    "    line = [\"Log Reg\", name, cvs.mean()]\n",
    "    results.append(line)\n",
    "    print(line)\n",
    "\n",
    "# Add l2  penalty. It will tune the parameter using cross validation\n",
    "logreg_l2 = LogisticRegressionCV(penalty=\"l2\", max_iter=1000)\n",
    "for X, y, name in zip(X_vals, y_vals, names):\n",
    "\n",
    "    cvs = cross_val_score(\n",
    "        estimator=logreg_l2, \n",
    "        X=X, \n",
    "        y=y, \n",
    "        scoring=\"accuracy\", \n",
    "        cv=10\n",
    "    )\n",
    "\n",
    "    line = [\"Log Reg l2\", name, cvs.mean()]\n",
    "    results.append(line)\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11780ad0",
   "metadata": {},
   "source": [
    "Convergence warning seems like a not a problem here since it performs well in cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b7c19a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Features</th>\n",
       "      <th>Dist Data</th>\n",
       "      <th>Mean Data</th>\n",
       "      <th>Min Max Mean Data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log Reg</th>\n",
       "      <td>0.857778</td>\n",
       "      <td>0.858889</td>\n",
       "      <td>0.868889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg l2</th>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.847778</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.824444</td>\n",
       "      <td>0.834444</td>\n",
       "      <td>0.856667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Features    Dist Data  Mean Data  Min Max Mean Data\n",
       "Method                                             \n",
       "Log Reg      0.857778   0.858889           0.868889\n",
       "Log Reg l2   0.911111   0.847778           0.911111\n",
       "RF           0.824444   0.834444           0.856667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results, columns=[\"Method\" , \"Features\", \"Accuracy\"])\n",
    "results = results.pivot(index=\"Method\", columns=\"Features\", values=\"Accuracy\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193049c",
   "metadata": {},
   "source": [
    "It appears that the best result comes from the l2 regularized Dist data and Min Max Mean Data. It appears that the missing quartiles does not add much information, it can be beacuse of the bags with a little instances which has quartiles that makes no sense. Also, having a regularized method as best makes sense because the number of data points are less than the number of features and a complex model can easily overfit. Regularization helps to control overfitting and obtain beter results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405a1fd",
   "metadata": {},
   "source": [
    "## Trying to Find the Most Usefull Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8d871",
   "metadata": {},
   "source": [
    "Another idea to determine the most usefull observation and use it as a bag representation. One way to do it is to use a distance metric to get the most distinct observatian from the mean of the data. This may help to select a proper observation in the bag and imporove the classification. This method can be improved by using an iterative approach to find the best representation however it would be a very detailed method that is out of scope of this task. Applying this method to the setting above would create bias since the distance should only be calculated in the training set. Therefore, we need to write cross validation steps on our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f16b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy:  0.7811111111111111\n",
      "Log Reg Accuracy:  0.8022222222222222\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=3136)\n",
    "bags = data.bag_id.unique()\n",
    "\n",
    "rf_res = []\n",
    "logreg_res = []\n",
    "# We need to split bags not observations in this case\n",
    "for train, test in cv.split(bags):\n",
    "    train, test = bags[train], bags[test]\n",
    "    train_data, test_data = data[data.bag_id.isin(train)].copy(), data[data.bag_id.isin(test)].copy()\n",
    "    # Scale data to avoid feature scales effect the distances\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data.drop(columns=[\"bag_id\", \"is_musk\"]))\n",
    "    scaled_test_data = scaler.transform(test_data.drop(columns=[\"bag_id\", \"is_musk\"]))\n",
    "    \n",
    "    # Classes are almost balanced how ever I believe getting mean class means is healtier\n",
    "    representative_vec = (\n",
    "        np.mean(scaled_train_data[train_data.is_musk], axis=0) \n",
    "        + np.mean(scaled_train_data[~train_data.is_musk], axis=0)\n",
    "    )/2\n",
    "    \n",
    "    # Calculate distances to representative vector\n",
    "    train_distances = np.sum(np.square(scaled_train_data - representative_vec), axis=1)\n",
    "    train_data[\"dist\"] = train_distances\n",
    "    test_distances = np.sum(np.square(scaled_test_data - representative_vec), axis=1)\n",
    "    test_data[\"dist\"] = test_distances\n",
    "    \n",
    "    # Get the most distinct observation in bag \n",
    "    train_data = train_data.loc[train_data.groupby(\"bag_id\").dist.idxmax()]\n",
    "    test_data = test_data.loc[test_data.groupby(\"bag_id\").dist.idxmax()]\n",
    "    \n",
    "    # Train RF with tuning & record accuracy\n",
    "    grid_searher = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "    grid_searher.fit(train_data.drop(columns=[\"bag_id\", \"is_musk\", \"dist\"]), train_data.is_musk)\n",
    "    rf_preds = grid_searher.predict(test_data.drop(columns=[\"bag_id\", \"is_musk\", \"dist\"]))\n",
    "    rf_acc = (rf_preds == test_data.is_musk).sum()/test_data.shape[0]\n",
    "    rf_res.append(rf_acc)\n",
    "    \n",
    "    # Train Log Reg and \n",
    "    logreg_classifier = LogisticRegressionCV(penalty=\"l2\", max_iter=1000, solver=\"lbfgs\")\n",
    "    logreg_classifier.fit(train_data.drop(columns=[\"bag_id\", \"is_musk\", \"dist\"]), train_data.is_musk)\n",
    "    \n",
    "    logreg_pred = logreg_classifier.predict(test_data.drop(columns=[\"bag_id\", \"is_musk\", \"dist\"]))\n",
    "    logreg_acc = (logreg_pred == test_data.is_musk).sum()/test_data.shape[0]\n",
    "    logreg_res.append(logreg_acc)\n",
    "    \n",
    "    \n",
    "print(\"RF Accuracy: \",np.mean(rf_res))\n",
    "print(\"Log Reg Accuracy: \",np.mean(logreg_res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8171dc",
   "metadata": {},
   "source": [
    "This method performs poor in terms of accuracy when it is compared to the distribution method. This result is reasanble since the method has some potential problems. First one is calculating the mean vector using the train data and we calculate a distance to a representation already includes that observation. This may cause a pottential overfitting. Secondly, just one of the instances in the bag may be causing a change in label and averaging may not make much sense. Additionaly label information can be hidden in multiple instances in the bag therefore by selecting just one we lost the information in other instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6faaa2",
   "metadata": {},
   "source": [
    "## Using distance to well known bags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8611f0",
   "metadata": {},
   "source": [
    "When the instances in the bags are a lot it is hard to say that these instances represents the label, however there are bags with two observations. One of these observations or both together must carry information about the label, therefore we can say that these bags are well known. And the distances from observations from this bags to the other bags might be usefull. However, there is still variable number of observations in the other bags. This issue can be solved by using the minimum distance to the representative bag mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e4b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Well Knowns in train_data:  27\n",
      "# of Well Knowns in train_data:  31\n",
      "# of Well Knowns in train_data:  29\n",
      "# of Well Knowns in train_data:  28\n",
      "# of Well Knowns in train_data:  28\n",
      "# of Well Knowns in train_data:  29\n",
      "# of Well Knowns in train_data:  30\n",
      "# of Well Knowns in train_data:  29\n",
      "# of Well Knowns in train_data:  29\n",
      "# of Well Knowns in train_data:  28\n",
      "RF Accuracy:  0.8788888888888889\n",
      "Log Reg Accuracy:  0.8355555555555556\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=3136)\n",
    "bags = data.bag_id.unique()\n",
    "train_cols = list(data.drop(columns=[\"bag_id\", \"is_musk\"]))\n",
    "\n",
    "rf_res = []\n",
    "logreg_res = []\n",
    "# We need to split bags not observations in this case\n",
    "for train, test in cv.split(bags):\n",
    "    train, test = bags[train], bags[test]\n",
    "    train_data, test_data = data[data.bag_id.isin(train)].copy(), data[data.bag_id.isin(test)].copy()\n",
    "    # Scale data to avoid feature scales effect the distances\n",
    "    \n",
    "    scaled_train_data = train_data[[\"bag_id\", \"is_musk\"]].copy()\n",
    "    scaled_test_data = test_data[[\"bag_id\", \"is_musk\"]].copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data[train_cols] = scaler.fit_transform(train_data.drop(columns=[\"bag_id\", \"is_musk\"]))\n",
    "    scaled_test_data[train_cols] = scaler.transform(test_data.drop(columns=[\"bag_id\", \"is_musk\"]))\n",
    "    \n",
    "    # Get well known bags in train data\n",
    "    bag_sizes = scaled_train_data.groupby(\"bag_id\").size()\n",
    "    well_known_bags = bag_sizes[bag_sizes == 2].index\n",
    "    print(\"# of Well Knowns in train_data: \", len(well_known_bags))\n",
    "    # Get the mean of the observations and create well known bag representations\n",
    "    well_known = (\n",
    "        scaled_train_data[scaled_train_data.bag_id.isin(well_known_bags)]\n",
    "    )\n",
    "    \n",
    "    train_dist_df = scaled_train_data[[\"bag_id\", \"is_musk\"]].copy()\n",
    "    test_dist_df = scaled_test_data[[\"bag_id\", \"is_musk\"]].copy()\n",
    "    well_known_bags = [f\"BAGF_{i}\" for i in range(len(well_known_bags)*2)]\n",
    "    train_dist_df[well_known_bags] = euclidean_distances(scaled_train_data[train_cols], well_known[train_cols])\n",
    "    test_dist_df[well_known_bags] = euclidean_distances(scaled_test_data[train_cols], well_known[train_cols])\n",
    "    \n",
    "    # Get the minimum distance to each well known\n",
    "    train_dist_df = train_dist_df.groupby(\"bag_id\").min().reset_index()\n",
    "    test_dist_df = test_dist_df.groupby(\"bag_id\").min().reset_index()\n",
    "    \n",
    "    \n",
    "    # Train RF with tuning & record accuracy\n",
    "    grid_searher = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "    grid_searher.fit(train_dist_df.drop(columns=[\"bag_id\", \"is_musk\"]), train_dist_df.is_musk)\n",
    "    rf_preds = grid_searher.predict(test_dist_df.drop(columns=[\"bag_id\", \"is_musk\"]))\n",
    "    rf_acc = (rf_preds == test_dist_df.is_musk).sum()/test_dist_df.shape[0]\n",
    "    rf_res.append(rf_acc)\n",
    "    \n",
    "    # Train Log Reg and \n",
    "    logreg_classifier = LogisticRegressionCV(penalty=\"l2\", max_iter=10000, solver=\"lbfgs\")\n",
    "    logreg_classifier.fit(train_dist_df.drop(columns=[\"bag_id\", \"is_musk\"]), train_dist_df.is_musk)\n",
    "    \n",
    "    logreg_pred = logreg_classifier.predict(test_dist_df.drop(columns=[\"bag_id\", \"is_musk\"]))\n",
    "    logreg_acc = (logreg_pred == test_dist_df.is_musk).sum()/test_dist_df.shape[0]\n",
    "    logreg_res.append(logreg_acc)\n",
    "    \n",
    "    \n",
    "print(\"RF Accuracy: \",np.mean(rf_res))\n",
    "print(\"Log Reg Accuracy: \",np.mean(logreg_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73756d52",
   "metadata": {},
   "source": [
    "This method performs better than the previous one and has less potential problems, the main problem may be changing well known points. However, it is still behind the distribution information method that we first tried. Since we moved to a much lower dimension the RF method was able to beat L2 regularized LogReg method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8b8650",
   "metadata": {},
   "source": [
    "In conclusion using Min Max Mean method with L2 regularized Logistic Regression performed best in 10 cv cross validation. Even though the data with quartiles has the same accuracy I selected the Min Max Mean data since it leads to a less complex model. Secondly RF with well known distances can be a good candidate and It just missclassifies one observation more. It may be considered as another choise or an ensemble of these two models can be considered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (foreflux_torch)",
   "language": "python",
   "name": "forelux_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
